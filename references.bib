%Paper over Google's deepmind systeem
@article{de2018clinically,
  title={Clinically applicable deep learning for diagnosis and referral in retinal disease},
  author={De Fauw, Jeffrey and Ledsam, Joseph R and Romera-Paredes, Bernardino and Nikolov, Stanislav and Tomasev, Nenad and Blackwell, Sam and Askham, Harry and Glorot, Xavier and O’Donoghue, Brendan and Visentin, Daniel and others},
  journal={Nature Medicine},
  pages={1},
  year={2018},
  publisher={Nature Publishing Group}
}

%Bench capon
@inproceedings{bench1993neural,
 author = {Bench-Capon, Trevor},
 title = {Neural Networks and Open Texture},
 booktitle = {{Proceedings of the 4th International Conference on Artificial Intelligence and Law}},
 series = {ICAIL '93},
 year = {1993},
 isbn = {0-89791-606-9},
 location = {Amsterdam, The Netherlands},
 pages = {292--297},
 numpages = {6},
 acmid = {159012},
 publisher = {ACM, New York},
 address = {New York, NY, USA},
}

%PADUA
@article{wardeh2009padua,
  title={Padua: a protocol for argumentation dialogue using association rules},
  author={Wardeh, Maya and Bench-Capon, Trevor and Coenen, Frans},
  journal={Artificial Intelligence and Law},
  volume={17},
  number={3},
  pages={183--215},
  year={2009},
  publisher={Springer}
}

%PISA
@incollection{wardeh2009pisa,
  title={PISA—pooling information from several agents: multiplayer argumentation from experience},
  author={Wardeh, Maya and Bench-Capon, Trevor and Coenen, Frans},
  booktitle={Research and Development in Intelligent Systems XXV},
  pages={133--146},
  year={2009},
  publisher={Springer}
}

%DARPA on XAI
@online{gunning2017explainable,
  author = {Gunning, David},
  title = {Explainable artificial intelligence ({XAI})},
  year = {2017},
  url = {https://www.darpa.mil/attachments/XAIProgramUpdate.pdf},
  urldate = {2018-06-15}
}


%Glass box system
@article{holzinger2017glass,
author = {Holzinger, Andreas and Plass, Markus and Holzinger, Katharina and Crisan, Gloria Cerasela and Pintea, Camelia and Palade, Vasile},
year = {2017},
month = {08},
pages = {},
title = {A glass-box interactive machine learning approach for solving NP-hard problems with the human-in-the-loop}
}

@article{edwards2017slave,
author = {Edwards, Lilian and Veale, Michael},
year = {2017},
volume = {16},
issue = {1},
pages = {18--84},
title = {Slave to the Algorithm? Why a Right to Explanation is Probably Not the Remedy You are Looking for},
journal = {Duke Law \& Technology Review}
}

%Neurorule
@article{lu2017neurorule,
author = {Lu, Hongjun and Setiono, Rudy and Liu, Huan},
year = {1996},
month = {11},
pages = {},
title = {NeuroRule: A Connectionist Approach to Data Mining},
booktitle = {Proc.Of the 21st VLDB Conf.}
}

%deepRED
@inproceedings{zilke2016deepred,
  title={DeepRED--Rule Extraction from Deep Neural Networks},
  author={Zilke, Jan Ruben and Menc{\'\i}a, Eneldo Loza and Janssen, Frederik},
  booktitle={International Conference on Discovery Science},
  pages={457--473},
  year={2016},
  organization={Springer, New York}
}


%Created the HeRO algorithm which uses defeasible logic to create a minimal theory. This creates a default class and some rules,  (basically AR) and uses it on the BC dataset. Performance is similar to my AR results on the dataset. 
@inproceedings{johnston2003induction,
  title={Induction of defeasible logic theories in the legal domain},
  author={Johnston, Benjamin and Governatori, Guido},
  booktitle={Proceedings of the 9th international conference on Artificial intelligence and law},
  pages={204--213},
  year={2003},
  organization={ACM, New York}
}

%Uses an argument version of the CN algorithm (decision rules) on the BC dataset. Arguments are based on domain knowledge, so useless for this situation. It compares HerO with the CN and the original BC nn!
@article{movzina2005argument,
  title={Argument based machine learning applied to law},
  author={Mo{\v{z}}ina, Martin and {\v{Z}}abkar, Jure and Bench-Capon, Trevor and Bratko, Ivan},
  journal={Artificial Intelligence and Law},
  volume={13},
  number={1},
  pages={53--73},
  year={2005},
  publisher={Springer, New York}
}

%The three main types of symmetric boolean functions
@incollection{wegener1987complexity,
  title={The complexity of symmetric boolean functions},
  author={Wegener, Ingo},
  booktitle={Computation theory and logic},
  pages={433--442},
  year={1987},
  publisher={Springer, New York}
}
% If fully connected feedforward networks are considered, the number of neurons in the hidden layer is reduced to N/2. In the case of fully connected networks with neurons connected in cascade, the minimum number of hidden neurons is between log2(N+1)-1 and log2(N+1). 
@inproceedings{wilamowski2003solving,
  title={Solving parity-N problems with feedforward neural networks},
  author={Wilamowski, Bodgan M and Hunter, David and Malinowski, Aleksander},
  booktitle={Neural Networks, 2003. Proceedings of the International Joint Conference on},
  volume={4},
  pages={2546--2551},
  year={2003},
  organization={IEEE, Piscataway}
}

%Equation used to predict DT relationship between dbs and acc
@book{michaelis1913kinetik,
  title={Die kinetik der invertinwirkung},
  author={Michaelis, Leonor and Menten, Maud Leonora},
  year={1913},
  publisher={Universit{\"a}tsbibliothek Johann Christian Senckenberg}
}

%Panda gibbon example
@article{yuan2017adversarial,
  title={Adversarial Examples: Attacks and Defenses for Deep Learning},
  author={Xiaoyong Yuan and Pan He and Qile Zhu and Rajendra Rana Bhat and Xiaolin Li},
  journal={CoRR},
  year={2017},
  volume={abs/1712.07107}
}

%CART algorithm
@book{breiman1984classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  year={1984},
  publisher={CRC press, Boca Raton}
}

%Universal approximators
@article{hornik1991approximation,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Hornik, Kurt},
  journal={Neural networks},
  volume={4},
  number={2},
  pages={251--257},
  year={1991},
  publisher={Elsevier}
}

%Learning of functions is improved by adding expert knowledge to framework directly, or implementing them as constraints in the training phase
@article{schwab2012learn,
  title={Learn more about your data: a symbolic regression knowledge representation framework},
  author={Schwab, Ingo and Link, Norbert},
  journal={International Journal of Intelligence Science},
  volume={2},
  number={04},
  pages={135},
  year={2012},
  publisher={Citeseer}
}

%double spiral problem
@article{Kaufmann1989Learning,
  title={“Learning to tell two spirals apart},
  author = {J Lang, Kevin and Witbrock, Michael},
  journal={Proceedings of 1988 Connectionists Models Summer School},
  number={04},
  pages={52-59},
  year={1989}
}